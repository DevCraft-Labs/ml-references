{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorlayerX for Tabular Data\n",
    "\n",
    "This notebook contains me learning TensorlayerX for tabular data. The case is using Default Credit Classifier based-on my previous ANN project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow;\n",
    "import pandas;\n",
    "from sklearn.model_selection import train_test_split;\n",
    "from sklearn.preprocessing import StandardScaler;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0      20000    2          2         1   24      2      2     -1     -1   \n",
       "1     120000    2          2         2   26     -1      2      0      0   \n",
       "2      90000    2          2         2   34      0      0      0      0   \n",
       "3      50000    2          2         1   37      0      0      0      0   \n",
       "4      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   PAY_5  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0     -2  ...          0          0          0         0       689         0   \n",
       "1      0  ...       3272       3455       3261         0      1000      1000   \n",
       "2      0  ...      14331      14948      15549      1518      1500      1000   \n",
       "3      0  ...      28314      28959      29547      2000      2019      1200   \n",
       "4      0  ...      20940      19146      19131      2000     36681     10000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  LABEL  \n",
       "0         0         0         0      1  \n",
       "1      1000         0      2000      1  \n",
       "2      1000      1000      5000      0  \n",
       "3      1100      1069      1000      0  \n",
       "4      9000       689       679      0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data from pre-cleaned csv file\n",
    "current_folder = \"/mnt/d/Code/College/Machine Learning/Team Assignment/Default Credit Scoring/\";\n",
    "# current_folder = \"\";\n",
    "dataframe = pandas.read_csv(current_folder + \"credit_card_clients.csv\");\n",
    "\n",
    "dataframe = dataframe.drop(columns = [\"ID\"]);\n",
    "\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping everything that other than mentioned above\n",
      "Dropping feature SEX since its not \"important\"\n",
      "Dropping feature EDUCATION since its not \"important\"\n",
      "Dropping feature MARRIAGE since its not \"important\"\n",
      "Dropping feature AGE since its not \"important\"\n",
      "Dropping feature BILL_AMT2 since its not \"important\"\n",
      "Dropping feature BILL_AMT3 since its not \"important\"\n",
      "Dropping feature BILL_AMT4 since its not \"important\"\n",
      "Dropping feature BILL_AMT5 since its not \"important\"\n",
      "Dropping feature BILL_AMT6 since its not \"important\"\n",
      "Dropping feature PAY_AMT1 since its not \"important\"\n",
      "Dropping feature PAY_AMT4 since its not \"important\"\n",
      "Dropping feature PAY_AMT5 since its not \"important\"\n",
      "Dropping feature PAY_AMT6 since its not \"important\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Dropping everything that other than mentioned above\");\n",
    "\n",
    "most_important_features = [\n",
    "    \"PAY_0\",\n",
    "    \"PAY_2\",\n",
    "    \"PAY_AMT2\",\n",
    "    \"LIMIT_BAL\",\n",
    "    \"PAY_AMT3\",\n",
    "    \"BILL_AMT1\",\n",
    "    \"PAY_3\",\n",
    "    \"PAY_4\",\n",
    "    \"PAY_6\",\n",
    "    \"PAY_5\",\n",
    "    \"LABEL\" # Don't :)\n",
    "];\n",
    "\n",
    "columns_to_be_dropped = [];\n",
    "for i in dataframe.columns:\n",
    "    if i not in most_important_features:\n",
    "        columns_to_be_dropped.append(i);\n",
    "        print(f\"Dropping feature {i} since its not \\\"important\\\"\");\n",
    "\n",
    "dataframe = dataframe.drop(columns = columns_to_be_dropped);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after cleaning:  (30000, 75)\n",
      "['LIMIT_BAL', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'LABEL', 'pay_0_-2', 'pay_0_-1', 'pay_0_0', 'pay_0_1', 'pay_0_2', 'pay_0_3', 'pay_0_4', 'pay_0_5', 'pay_0_6', 'pay_0_7', 'pay_0_8', 'pay_2_-2', 'pay_2_-1', 'pay_2_0', 'pay_2_1', 'pay_2_2', 'pay_2_3', 'pay_2_4', 'pay_2_5', 'pay_2_6', 'pay_2_7', 'pay_2_8', 'pay_3_-2', 'pay_3_-1', 'pay_3_0', 'pay_3_1', 'pay_3_2', 'pay_3_3', 'pay_3_4', 'pay_3_5', 'pay_3_6', 'pay_3_7', 'pay_3_8', 'pay_4_-2', 'pay_4_-1', 'pay_4_0', 'pay_4_1', 'pay_4_2', 'pay_4_3', 'pay_4_4', 'pay_4_5', 'pay_4_6', 'pay_4_7', 'pay_4_8', 'pay_5_-2', 'pay_5_-1', 'pay_5_0', 'pay_5_2', 'pay_5_3', 'pay_5_4', 'pay_5_5', 'pay_5_6', 'pay_5_7', 'pay_5_8', 'pay_6_-2', 'pay_6_-1', 'pay_6_0', 'pay_6_2', 'pay_6_3', 'pay_6_4', 'pay_6_5', 'pay_6_6', 'pay_6_7', 'pay_6_8']\n"
     ]
    }
   ],
   "source": [
    "# Make one hot encoding for PAY_0 to 6 since the data is an ordinal data\n",
    "hot_encoded_pay_0 = pandas.get_dummies(dataframe['PAY_0'], prefix = \"pay_0\");\n",
    "hot_encoded_pay_2 = pandas.get_dummies(dataframe['PAY_2'], prefix = \"pay_2\");\n",
    "hot_encoded_pay_3 = pandas.get_dummies(dataframe['PAY_3'], prefix = \"pay_3\");\n",
    "hot_encoded_pay_4 = pandas.get_dummies(dataframe['PAY_4'], prefix = \"pay_4\");\n",
    "hot_encoded_pay_5 = pandas.get_dummies(dataframe['PAY_5'], prefix = \"pay_5\");\n",
    "hot_encoded_pay_6 = pandas.get_dummies(dataframe['PAY_6'], prefix = \"pay_6\");\n",
    "\n",
    "# Merge the hot_encoded with the main dataframe\n",
    "for i in [hot_encoded_pay_0, hot_encoded_pay_2, hot_encoded_pay_3, hot_encoded_pay_4, hot_encoded_pay_5, hot_encoded_pay_6]:\n",
    "    dataframe = pandas.concat([dataframe, i], axis = 1);\n",
    "\n",
    "print(\"Data after cleaning: \", dataframe.shape);\n",
    "print(dataframe.columns.tolist());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape:  (30000, 68)\n"
     ]
    }
   ],
   "source": [
    "# Define label data\n",
    "label = dataframe['LABEL'];\n",
    "\n",
    "# Drop ID, SEX, EDUCATION, MARRIAGE, and LABEL from dataframe for features\n",
    "features = dataframe.drop(columns=['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', \"LABEL\"]);\n",
    "\n",
    "# Typecasting all values within to int64 because ANN need to be standardized\n",
    "\n",
    "for i in dataframe.columns:\n",
    "    dataframe[i] = dataframe[i].astype(int);\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "feature_train, feature_test, label_train, label_test = train_test_split(\n",
    "    features, \n",
    "    label, \n",
    "    train_size = 0.7, \n",
    "    test_size = 0.3, \n",
    "    random_state = 42\n",
    ");\n",
    "\n",
    "feature_validation, feature_test, label_validation, label_test = train_test_split(\n",
    "    feature_test, \n",
    "    label_test, \n",
    "    test_size=0.5, \n",
    "    random_state = 42\n",
    ");\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler();\n",
    "feature_train_scaled = scaler.fit_transform(feature_train);\n",
    "feature_validation_scaled = scaler.fit_transform(feature_validation);\n",
    "feature_test_scaled = scaler.transform(feature_test);\n",
    "\n",
    "print(\"Features shape: \", features.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorlayerx;\n",
    "import os;\n",
    "from tensorlayerx.nn import Module, Sequential, Input, Linear, Sigmoid;\n",
    "from tensorlayerx.model import Model;\n",
    "from tensorlayerx.optimizers import Adam;\n",
    "from tensorlayerx.losses import binary_cross_entropy;\n",
    "from tensorlayerx.metrics import acc;\n",
    "from tensorlayerx.dataflow import IterableDataset;\n",
    "os.environ[\"TL_BACKEND\"] = \"tensorflow\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetLoader(IterableDataset):\n",
    "    def __init__(self, feature, label):\n",
    "        self.data = feature;\n",
    "        self.label = label;\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index].astype(\"float32\");\n",
    "        label = self.label[index].astype(\"float32\");\n",
    "\n",
    "        return data, label;\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data);\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(len(self.data)):\n",
    "            yield self.data[i].astype(\"float32\"), self.label[i].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TLX] Input  _inputlayer_2: [68]\n",
      "[TLX] Linear  linear_104: 64 Sigmoid\n",
      "[TLX] Linear  linear_105: 32 Sigmoid\n",
      "[TLX] Linear  linear_106: 1 Sigmoid\n"
     ]
    }
   ],
   "source": [
    "class ANNTlx (Module):\n",
    "    def __init__(self):\n",
    "        super (ANNTlx, self).__init__();\n",
    "\n",
    "        self.input = Input(shape = [64,68]);\n",
    "\n",
    "        self.dense1 = Linear(in_features = 68, out_features = 64, act = Sigmoid);\n",
    "        self.dense2 = Linear(in_features = 64, out_features = 32, act = Sigmoid);\n",
    "\n",
    "        self.output = Linear(in_features = 32, out_features = 1, act = Sigmoid);\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.dense1(x);\n",
    "        x = self.dense2(x);\n",
    "        out = self.output(x);\n",
    "\n",
    "        return out;\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.input(x);\n",
    "        x = self.dense1(x);\n",
    "        x = self.dense2(x);\n",
    "        out = self.output(x);\n",
    "\n",
    "        return out;\n",
    "        \n",
    "network = ANNTlx();\n",
    "loss_function = binary_cross_entropy;\n",
    "metric_function = acc;\n",
    "optimizer = Adam(lr = 1e-3);\n",
    "\n",
    "model = Model(network, loss_fn = loss_function, optimizer = optimizer, metric_function = metric_function);\n",
    "train_dataset = DatasetLoader(feature_train_scaled, label_train);\n",
    "val_dataset = DatasetLoader(feature_validation_scaled, label_validation);\n",
    "test_dataset = DatasetLoader(feature_test_scaled, label_test);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4c78edd6d44f8493f482c60c5dd0c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:GPU:0}} In[0] and In[1] has different ndims: [68] vs. [68,64] [Op:MatMul] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_freq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_team/lib/python3.10/site-packages/tensorlayerx/model/core.py:99\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, n_epoch, train_dataset, test_dataset, print_train_batch, print_freq)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected type in (train_dataset, Iterable), but got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(train_dataset)))\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tlx\u001b[38;5;241m.\u001b[39mBACKEND \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprint_train_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_train_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tlx\u001b[38;5;241m.\u001b[39mBACKEND \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmindspore\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mms_train(\n\u001b[1;32m    106\u001b[0m         n_epoch\u001b[38;5;241m=\u001b[39mn_epoch, train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset, network\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork, loss_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn,\n\u001b[1;32m    107\u001b[0m         train_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_weights, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics,\n\u001b[1;32m    108\u001b[0m         print_train_batch\u001b[38;5;241m=\u001b[39mprint_train_batch, print_freq\u001b[38;5;241m=\u001b[39mprint_freq, test_dataset\u001b[38;5;241m=\u001b[39mtest_dataset\n\u001b[1;32m    109\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_team/lib/python3.10/site-packages/tensorlayerx/model/core.py:290\u001b[0m, in \u001b[0;36mModel.tf_train\u001b[0;34m(self, n_epoch, train_dataset, network, loss_fn, train_weights, optimizer, metrics, print_train_batch, print_freq, test_dataset)\u001b[0m\n\u001b[1;32m    286\u001b[0m network\u001b[38;5;241m.\u001b[39mset_train()\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;66;03m# compute outputs\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m     _logits \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;66;03m# compute loss and update model\u001b[39;00m\n\u001b[1;32m    292\u001b[0m     _loss_ce \u001b[38;5;241m=\u001b[39m loss_fn(_logits, y_batch)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_team/lib/python3.10/site-packages/tensorlayerx/nn/core/core_tensorflow.py:173\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_weights_check()\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "Cell \u001b[0;32mIn[86], line 13\u001b[0m, in \u001b[0;36mANNTlx.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense2(x);\n\u001b[1;32m     15\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(x);\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_team/lib/python3.10/site-packages/tensorlayerx/nn/core/core_tensorflow.py:173\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_weights_check()\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_team/lib/python3.10/site-packages/tensorlayerx/nn/layers/linear/base_linear.py:112\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_built \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_init_flag:\n\u001b[1;32m    114\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_add(z, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbiases)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_team/lib/python3.10/site-packages/tensorlayerx/backend/ops/tensorflow_backend.py:506\u001b[0m, in \u001b[0;36mMatMul.__call__\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, a, b):\n\u001b[0;32m--> 506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose_b\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_team/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_team/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_team/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:5883\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5882\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5883\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:GPU:0}} In[0] and In[1] has different ndims: [68] vs. [68,64] [Op:MatMul] name: "
     ]
    }
   ],
   "source": [
    "model.train(n_epoch = 10, train_dataset = train_dataset, test_dataset = val_dataset, print_freq = 1);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
