{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow;\n",
    "import os;\n",
    "\n",
    "os.environ[\"TL_BACKEND\"] = \"tensorflow\";\n",
    "\n",
    "import tensorlayerx;\n",
    "import numpy;\n",
    "\n",
    "from tensorflow.keras.datasets import mnist;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tensorflow.config.list_physical_devices('GPU'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data();\n",
    "\n",
    "# Split the test and val by 50:50\n",
    "test_val_images_split = numpy.array_split(test_images, 2);\n",
    "test_val_labels_split = numpy.array_split(test_labels, 2);\n",
    "\n",
    "test_images = test_val_images_split[0];\n",
    "test_labels = test_val_labels_split[0];\n",
    "\n",
    "val_images = test_val_images_split[1];\n",
    "val_labels = test_val_labels_split[1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall step 1\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255;\n",
    "test_images = test_images.reshape((5000, 28, 28, 1)).astype('float32') / 255;\n",
    "val_images = val_images.reshape((5000, 28, 28, 1)).astype('float32') / 255;\n",
    "\n",
    "# Recall step 2\n",
    "train_labels = tensorflow.one_hot(train_labels, depth = 10);\n",
    "test_labels = tensorflow.one_hot(test_labels, depth = 10);\n",
    "val_labels = tensorflow.one_hot(val_labels, depth = 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorlayerx.nn import Sequential, Conv2d, MaxPool2d, Flatten, Linear;\n",
    "from tensorlayerx.model import TrainOneStep;\n",
    "from tensorlayerx.optimizers import Adam;\n",
    "from tensorlayerx.losses import cross_entropy_seq;\n",
    "from tqdm import tqdm;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel:\n",
    "    def __init__(self):\n",
    "        self.conv1 = Conv2d(out_channels = 32, kernel_size = (3, 3), act = \"relu\", in_channels = 1, name = \"conv1\");\n",
    "        self.pool1 = MaxPool2d(kernel_size = (2, 2), name = \"pool1\");\n",
    "\n",
    "        self.conv2 = Conv2d(out_channels = 32, kernel_size = (3, 3), act = \"relu\", name = \"conv2\");\n",
    "        self.pool2 = MaxPool2d(kernel_size = (2, 2), name = \"pool2\");\n",
    "\n",
    "        self.flat = Flatten(name = \"flat\");\n",
    "\n",
    "        self.dense = Linear(out_features = 64, act = \"relu\", name = \"dense\");\n",
    "\n",
    "        self.output = Linear(out_features = 3, act = \"relu\", name = \"output\");\n",
    "    \n",
    "    def compile(self):\n",
    "        model = Sequential([\n",
    "            self.conv1,\n",
    "            self.pool1,\n",
    "            self.conv2,\n",
    "            self.pool2,\n",
    "            self.flat,\n",
    "            self.dense,\n",
    "            self.output\n",
    "        ]);\n",
    "\n",
    "        print(\"------------------------------------------------\")\n",
    "        print(\"               MNIST Tensorlayerx               \");\n",
    "        print(\"------------------------------------------------\")\n",
    "        print(\"Neuron: \", sum(layer.out_features for layer in model if hasattr(layer, 'out_features')))\n",
    "        print(model);\n",
    "\n",
    "        return model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManualTrainer:\n",
    "\n",
    "    \"\"\"\n",
    "    ManualTrainer\n",
    "\n",
    "    This class is mimicing the Tensorflow's automatic fit. \n",
    "    However, since the adversarial training algorithm may requires TrainOneStep.\n",
    "\n",
    "    @params\n",
    "        epoch: number of epoch\n",
    "        batch_size: total data per training minibatch (For every epoch elapsed, train the data with minibatches.)\n",
    "        model: model to be trained (tensorlayerx.nn.Sequential)\n",
    "        optimizer: optimizer algorithm to be used for training (tensorlayerx.optimizers)\n",
    "        loss: loss function to be used for training (tensorlayerx.losses)\n",
    "        \n",
    "        ----------------------------------------------------------------\n",
    "        Every parameters below are defined as array length of 2:\n",
    "        train_set -> [ [X_set], [Y_set] ]\n",
    "        val_set -> [ [X_set], [Y_set] ]\n",
    "    \"\"\"\n",
    "    def __init__(self, epoch: int, batch_size: int, model, optimizer, loss, train_set, val_set = []):\n",
    "        self.epoch = epoch;\n",
    "        self.batch_size = batch_size;\n",
    "        self.optimizer = optimizer;\n",
    "        self.loss = loss;\n",
    "        self.model = model;\n",
    "        \n",
    "        # Dataset\n",
    "        self.train_set = [\n",
    "            [train_set[0]],\n",
    "            [train_set[1]],\n",
    "        ];\n",
    "\n",
    "        # If the validation is not set, then the validation set will be using training set instead\n",
    "        self.val_set = [\n",
    "            [train_set[0]] if (len(val_set) == 0) else [val_set[0]],\n",
    "            [train_set[1]] if (len(val_set) == 0) else [val_set[1]],\n",
    "        ];\n",
    "\n",
    "\n",
    "        self.average_training_loss = 0.0;\n",
    "        self.validation_loss = 0.0;\n",
    "        self.validation_accuracy = 0.0;\n",
    "\n",
    "        # Train One Step\n",
    "    \n",
    "    def fitting(self):\n",
    "        loss = 0.0;\n",
    "\n",
    "        feed_forward = TrainOneStep(self.model, optimizer = self.optimizer, train_weights = True);\n",
    "\n",
    "        # Start of epoch\n",
    "        for epoch in tqdm(range(self.epoch)):\n",
    "            epoch_loss = 0.0;\n",
    "\n",
    "            # Start of batch training\n",
    "            for batch in range(self.batch_size):\n",
    "                start_dataset_index = batch * self.batch_size;\n",
    "                end_dataset_index = (batch + 1) * self.batch_size;\n",
    "\n",
    "                feature_set = self.train_set[0][start_dataset_index:end_dataset_index];\n",
    "                label_set = self.train_set[1][start_dataset_index:end_dataset_index];\n",
    "\n",
    "                training_loss_value = feed_forward(feature_set, label_set);\n",
    "\n",
    "                epoch_loss += training_loss_value;\n",
    "            # End of batch training\n",
    "            \n",
    "            self.average_training_loss = epoch_loss / self.batch_size;\n",
    "\n",
    "            # The loss now count with validation set \n",
    "            loss, accuracy = model.evaluate(self.val_set[0], self.val_set[1]);\n",
    "\n",
    "            self.validation_loss = loss;\n",
    "            self.validation_accuracy = accuracy;\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{self.epoch} | loss: {self.validation_loss} | accuracy: {self.validation_accuracy}\")\n",
    "\n",
    "        # End of epoch\n",
    "        return self.model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TLX] Conv2d conv1: out_channels : 32 kernel_size: (3, 3) stride: (1, 1) pad: SAME act: ReLU\n",
      "[TLX] MaxPool2d pool1: kernel_size: (2, 2) stride: (2, 2) padding: SAME return_mask: False\n",
      "[TLX] Conv2d conv2: out_channels : 32 kernel_size: (3, 3) stride: (1, 1) pad: SAME act: ReLU\n",
      "[TLX] MaxPool2d pool2: kernel_size: (2, 2) stride: (2, 2) padding: SAME return_mask: False\n",
      "[TLX] Flatten flat:\n",
      "[TLX] Linear  dense: 64 ReLU\n",
      "[TLX] Linear  output: 3 ReLU\n",
      "------------------------------------------------\n",
      "               MNIST Tensorlayerx               \n",
      "------------------------------------------------\n",
      "Neuron:  67\n",
      "Sequential<\n",
      "  (0): Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3), stride=(1, 1), padding=SAME, ReLU, name='conv1')\n",
      "  (1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=SAME, return_mask=False, name='pool1')\n",
      "  (2): Conv2d(in_channels=None, out_channels=32, kernel_size=(3, 3), stride=(1, 1), padding=SAME, ReLU, name='conv2')\n",
      "  (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=SAME, return_mask=False, name='pool2')\n",
      "  (4): Flatten(name='flat')\n",
      "  (5): Linear(out_features=64, ReLU, name='dense')\n",
      "  (6): Linear(out_features=3, ReLU, name='output')\n",
      "  >\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TrainOneStep.__call__() missing 1 required positional argument: 'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[223], line 14\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m cnn\u001b[38;5;241m.\u001b[39mcompile();\n\u001b[1;32m      4\u001b[0m trainer \u001b[38;5;241m=\u001b[39m ManualTrainer(\n\u001b[1;32m      5\u001b[0m     epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, \n\u001b[1;32m      6\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     val_set \u001b[38;5;241m=\u001b[39m [val_images, val_labels]\n\u001b[1;32m     12\u001b[0m );\n\u001b[0;32m---> 14\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfitting\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m     15\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_images, test_labels)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[222], line 64\u001b[0m, in \u001b[0;36mManualTrainer.fitting\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m     feature_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_set[\u001b[38;5;241m0\u001b[39m][start_dataset_index:end_dataset_index];\n\u001b[1;32m     62\u001b[0m     label_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_set[\u001b[38;5;241m1\u001b[39m][start_dataset_index:end_dataset_index];\n\u001b[0;32m---> 64\u001b[0m     training_loss_value \u001b[38;5;241m=\u001b[39m \u001b[43mfeed_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_set\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m     66\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m training_loss_value;\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# End of batch training\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: TrainOneStep.__call__() missing 1 required positional argument: 'label'"
     ]
    }
   ],
   "source": [
    "cnn = CNNModel();\n",
    "model = cnn.compile();\n",
    "\n",
    "trainer = ManualTrainer(\n",
    "    epoch = 5, \n",
    "    batch_size = 64, \n",
    "    optimizer = Adam(lr = 1e-3),\n",
    "    loss = cross_entropy_seq,\n",
    "    model = model,\n",
    "    train_set = [train_images, train_labels],\n",
    "    val_set = [val_images, val_labels]\n",
    ");\n",
    "\n",
    "model = trainer.fitting();\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
